# DeepScrape - Web Crawler, Image Extractor & PDF Renderer

## Overview

**DeepScrape** is a command-line **web crawler** designed to:

- Fetch **HTML pages**
- Extract **image URLs**
- **Download images** (optional)
- **Process sitemaps** automatically
- **Save PDFs of fully rendered pages**
- **Limit request rate** to avoid detection

**Why Use DeepScrape?**

âœ” **Organized Output** â€“ Saves files into structured folders  
âœ” **Sitemap Support** â€“ Automatically extracts URLs from sitemaps  
âœ” **PDF Rendering** â€“ Captures fully rendered pages with Puppeteer  
âœ” **Rate Limiting** â€“ Prevents excessive requests  
âœ” **Simple CLI** â€“ Easy-to-use commands

---

## ğŸ“¥ Installation

### Prerequisites

Ensure **Node.js** is installed:

```sh
node -v  # Check Node.js version
npm -v   # Check npm version
```

### Clone the Repository

```sh
git clone https://github.com/haigis/DeepScrape.git
cd DeepScrape
```

### Install Dependencies

```sh
npm install
```

---

## ğŸš€ Usage

### Basic Web Scrape

```sh
node deepscrape.cjs
```

This will:

âœ… Create a new folder in `output/` (e.g., `output/scan_YYYYMMDD_HHMMSS_<scanID>/`).  
âœ… Save HTML files in `html/`.  
âœ… Extract image URLs into `images.txt`.

---

## ğŸ”§ Command Options

### 1ï¸âƒ£ Show Help Menu

```sh
node deepscrape.cjs -h
```

### 2ï¸âƒ£ Add a Custom Scan Name

```sh
node deepscrape.cjs -n MyCustomScan
```

Example folder:

```
output/scan_YYYYMMDD_HHMMSS_<scanID>_MyCustomScan/
```

### 3ï¸âƒ£ Process a Sitemap

```sh
node deepscrape.cjs -sm https://example.com/sitemap.xml
```

This extracts URLs from a **sitemap.xml** and processes them.

### 4ï¸âƒ£ Process URLs from a File

```sh
node deepscrape.cjs -f urls.txt
```

Scrapes all URLs listed in `urls.txt`.

### 5ï¸âƒ£ Save PDFs of Rendered Pages

```sh
node deepscrape.cjs --pdf -n pdfscan
```

This will:

âœ… Load each page in **Puppeteer**  
âœ… Save it as a **PDF** inside the `pdf/` folder

### 6ï¸âƒ£ Download Images from the Last Scan

```sh
node deepscrape.cjs --download-images
```

### 7ï¸âƒ£ Set a Rate Limit (in ms)

```sh
node deepscrape.cjs --rate-limit 2000
```

(Default: **1000ms** delay between requests)

---

## ğŸ“‚ Output Structure

After running DeepScrape, results are stored inside an **organized folder**:

```
output/
â”‚â”€â”€ scan_YYYYMMDD_HHMMSS_<scanID>_MyCustomScan/
â”‚   â”‚â”€â”€ html/          # Saved HTML files
â”‚   â”‚â”€â”€ images.txt     # Extracted image URLs
â”‚   â”‚â”€â”€ images/        # (Optional) Downloaded images
â”‚   â””â”€â”€ pdf/           # (Optional) Rendered PDFs
```

---

## ğŸ‘¨â€ğŸ’» Contributing

âœ” Open an **issue** for bug reports  
âœ” Submit **pull requests** for improvements

---

## ğŸ“œ License

MIT License Â© 2024 Haigis/DeepScrape

---

### ğŸš€ Next Steps

- **Commit & Push Version 2.5 to GitHub**

```sh
git add .
git commit -m "DeepScrape v2.5 - PDF support, fixes, improvements"
git push origin main
```

- **Update the release on GitHub** with the latest version.
